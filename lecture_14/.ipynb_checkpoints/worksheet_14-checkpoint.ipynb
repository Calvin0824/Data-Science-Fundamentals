{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 14\n",
    "\n",
    "Name: Calvin Li  \n",
    "UID: U51621195\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Naive Bayes\n",
    "- Model Evaluation\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "| Attribute A | Attribute B | Attribute C | Class |\n",
    "|-------------|-------------|-------------|-------|\n",
    "| Yes         | Single      | High        | No    |\n",
    "| No          | Married     | Mid         | No    |\n",
    "| No          | Single      | Low         | No    |\n",
    "| Yes         | Married     | High        | No    |\n",
    "| No          | Divorced    | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| Yes         | Divorced    | High        | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "\n",
    "a) Compute the following probabilities:\n",
    "\n",
    "- P(Attribute A = Yes | Class = No)\n",
    "- P(Attribute B = Divorced | Class = Yes)\n",
    "- P(Attribute C = High | Class = No)\n",
    "- P(Attribute C = Mid | Class = Yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(Attribute A = Yes | Class = No) = $\\frac{3}{7}$  \n",
    "P(Attribute B = Divorced | Class = Yes) = $\\frac{1}{3}$  \n",
    "P(Attribute C = High | Class = No) = $\\frac{3}{7}$  \n",
    "P(Attribute C = Mid | Class = Yes) = $\\frac{3}{4}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Classify the following unseen records:\n",
    "\n",
    "- (Yes, Married, Mid)\n",
    "- (No, Divorced, High)\n",
    "- (No, Single, High)\n",
    "- (No, Divorced, Low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Yes, Married, Mid) = No  \n",
    "(No, Divorced, High) = No  \n",
    "(No, Single, High) = No  \n",
    "(No, Divorced, Low) = No "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "a) Write a function to generate the confusion matrix for a list of actual classes and a list of predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 1], [3, 4]]\n"
     ]
    }
   ],
   "source": [
    "actual_class = [\"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\"]\n",
    "predicted_class = [\"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\"]\n",
    "\n",
    "def confusion_matrix(actual, predicted):\n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "    for i in range(len(actual_class)):\n",
    "        if actual[i] == \"Yes\" and predicted[i] == \"Yes\":\n",
    "            TP += 1\n",
    "        elif actual[i] == \"Yes\" and predicted[i] == \"No\":\n",
    "            FN += 1\n",
    "        elif actual[i] == \"No\" and predicted[i] == \"Yes\":\n",
    "            FP += 1\n",
    "        elif actual[i] == \"No\" and predicted[i] == \"No\":\n",
    "            TN += 1\n",
    "    return [[TP, FN], [FP, TN]]\n",
    "\n",
    "print(confusion_matrix(actual_class, predicted_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Assume you have the following Cost Matrix:\n",
    "\n",
    "|            | predicted = Y | predicted = N |\n",
    "|------------|---------------|---------------|\n",
    "| actual = Y |       -1      |       5       |\n",
    "| actual = N |        10     |       0       |\n",
    "\n",
    "What is the cost of the above classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP cost = 2 * -1 = -2  \n",
    "FP cost = 3 * 10 = 30  \n",
    "FN cost = 1 * 5 = 5  \n",
    "TN cost = 4 * 0 = 0\n",
    "\n",
    "Overall cost: 30 + 5 + (-2) + 0 = 35 - 2 = 33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a function that takes in the actual values, the predictions, and a cost matrix and outputs a cost. Test it on the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "cost_matrix = [[-1, 5],[10, 0]]\n",
    "\n",
    "def cost(actual, predicted, cost_matrix):\n",
    "    total = 0\n",
    "    for i in range(len(actual_class)):\n",
    "        if actual[i] == \"Yes\" and predicted[i] == \"Yes\":\n",
    "            total += cost_matrix[0][0]\n",
    "        elif actual[i] == \"Yes\" and predicted[i] == \"No\":\n",
    "            total += cost_matrix[0][1]\n",
    "        elif actual[i] == \"No\" and predicted[i] == \"Yes\":\n",
    "            total += cost_matrix[1][0]\n",
    "        elif actual[i] == \"No\" and predicted[i] == \"No\":\n",
    "            total += cost_matrix[1][1]\n",
    "    return total\n",
    "\n",
    "print(cost(actual_class, predicted_class, cost_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Implement functions for the following:\n",
    "\n",
    "- accuracy\n",
    "- precision\n",
    "- recall\n",
    "- f-measure\n",
    "\n",
    "and apply them to the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6\n",
      "precision: 0.4\n",
      "recall: 0.6666666666666666\n",
      "f-measure: 0.5\n"
     ]
    }
   ],
   "source": [
    "def accuracy(confusion):\n",
    "    a = confusion[0][0]\n",
    "    b = confusion[0][1]\n",
    "    c = confusion[1][0]\n",
    "    d = confusion[1][1]\n",
    "    return (a + d) / (a + b + c + d)\n",
    "\n",
    "def precision(confusion):\n",
    "    a = confusion[0][0]\n",
    "    c = confusion[1][0]\n",
    "    return a / (a + c)\n",
    "\n",
    "def recall(confusion):\n",
    "    a = confusion[0][0]\n",
    "    b = confusion[0][1]\n",
    "    return a / (a + b)\n",
    "\n",
    "def f_measure(precision, recall):\n",
    "    return (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "confusion = confusion_matrix(actual_class, predicted_class)\n",
    "precision_value = precision(confusion)\n",
    "recall_value = recall(confusion)\n",
    "\n",
    "print(\"accuracy:\", accuracy(confusion))\n",
    "print(\"precision:\", precision(confusion))\n",
    "print(\"recall:\", recall(confusion))\n",
    "print(\"f-measure:\", f_measure(precision_value, recall_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge (Midterm prep part 2)\n",
    "\n",
    "In this exercise you will update your submission to the titanic competition.\n",
    "\n",
    "a) First let's add new numerical features / columns to the datasets that might be related to the survival of individuals.\n",
    "\n",
    "- `has_cabin` should have a value of 0 if the `cabin` feature is `nan` and 1 otherwise\n",
    "- `family_members` should have the total number of family members (by combining `SibSp` and `Parch`)\n",
    "- `title_type`: from the title extracted from the name, we will categorize it into 2 types: `common` for titles that many passengers have, `rare` for titles that few passengers have. Map `common` to 1 and `rare` to 0. Describe what threshold you used to define `common` and `rare` titles and how you found it.\n",
    "- `fare_type`: using Kmeans clustering on the fare column, find an appropriate number of clusters / groups of similar fares. Using the clusters you created, `fare_price` should be an ordinal variable that represents the expensiveness of the fare. For example if you split fare into 3 clusters ( 0 - 15, 15 - 40, and 40+ ) then the `fare_price` value should be `0` for `fare` values 0 - 15, `1` for 15 - 40, and `2` for 40+.\n",
    "- Create an addition two numerical features of your invention that you think could be relevant to the survival of individuals.\n",
    "\n",
    "Note: The features must be numerical because the sklearn `DecisionTreeClassifier` can only take on numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "#setting Cabin to either 1 or 0\n",
    "train_df.loc[train_df[\"Cabin\"].notnull(), \"Cabin\"] = 1\n",
    "train_df[\"Cabin\"].fillna(0, inplace=True)\n",
    "#adding Family members\n",
    "train_df[\"family_members\"] = train_df[\"SibSp\"] + train_df[\"Parch\"]\n",
    "#Any title that has a frequency of over 100 is considered common\n",
    "#These are Mr, Miss, and Mrs\n",
    "train_df[\"title_type\"] = train_df[\"Name\"].str.extract(\" ([A-Za-z]+)\\.\", expand=False)\n",
    "frequency = train_df['title_type'].value_counts()\n",
    "common = frequency[frequency > 100].index\n",
    "train_df[\"title_type\"] = train_df[\"title_type\"].apply(lambda x: 1 if x in common else 0)\n",
    "#fare_price\n",
    "fare_data = np.array(train_df[\"Fare\"]).reshape(-1, 1)\n",
    "k_means = KMeans(n_clusters=5, random_state=50, n_init=10)\n",
    "k_means.fit(fare_data)\n",
    "centroids = k_means.cluster_centers_\n",
    "train_df[\"fare_price\"] = k_means.predict(fare_data)\n",
    "#categorizing the age\n",
    "train_df[\"Age\"].fillna(train_df[\"Age\"].mean(), inplace=True)\n",
    "age_bins = [0, 10, 18, 60, float('inf')]\n",
    "age_labels = [\"child\", \"teen\", \"adult\", \"elder\"]\n",
    "train_df[\"Categorized_Age\"] = pd.cut(train_df[\"Age\"], bins=age_bins, labels=age_labels, right=True)\n",
    "#changing categorical into numerical\n",
    "le = LabelEncoder()\n",
    "#female is 0 and male is 1\n",
    "train_df[\"Sex\"] = le.fit_transform(train_df[\"Sex\"])\n",
    "#adult = 0, child = 1, teen = 3, elder = 2\n",
    "train_df[\"Categorized_Age\"] = le.fit_transform(train_df[\"Categorized_Age\"])\n",
    "survived = train_df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Using a method covered in class, tune the parameters of a decision tree model on the titanic dataset (containing all numerical features including the ones you added above). Evaluate this model locally and report it's performance.\n",
    "\n",
    "Note: make sure you are not tuning your parameters on the same dataset you are using to evaluate the model. Also explain how you know you are not overfitting to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Accuracy: 0.8100558659217877\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         0\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_df = train_df.drop([\"Name\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Embarked\", \"Survived\"], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_df, survived, test_size=0.2, random_state=50)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 9, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_dt_classifier = DecisionTreeClassifier(**best_params)\n",
    "best_dt_classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = best_dt_classifier.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "#every new feature added to train, add to test \n",
    "#setting Cabin to either 1 or 0\n",
    "test_df.loc[test_df[\"Cabin\"].notnull(), \"Cabin\"] = 1\n",
    "test_df[\"Cabin\"].fillna(0, inplace=True)\n",
    "#adding Family members\n",
    "test_df[\"family_members\"] = test_df[\"SibSp\"] + test_df[\"Parch\"]\n",
    "#Any title that has a frequency of over 100 is considered common\n",
    "#These are Mr, Miss, and Mrs\n",
    "test_df[\"title_type\"] = test_df[\"Name\"].str.extract(\" ([A-Za-z]+)\\.\", expand=False)\n",
    "frequency = test_df[\"title_type\"].value_counts()\n",
    "common = frequency[frequency > 100].index\n",
    "test_df[\"title_type\"] = test_df[\"title_type\"].apply(lambda x: 1 if x in common else 0)\n",
    "#fare_price\n",
    "test_df[\"Fare\"].fillna(test_df[\"Fare\"].mean(), inplace=True)\n",
    "fare_data = np.array(test_df[\"Fare\"]).reshape(-1, 1)\n",
    "k_means = KMeans(n_clusters=5, random_state=50, n_init=10)\n",
    "k_means.fit(fare_data)\n",
    "centroids = k_means.cluster_centers_\n",
    "test_df[\"fare_price\"] = k_means.predict(fare_data)\n",
    "#categorizing the age\n",
    "test_df[\"Age\"].fillna(test_df[\"Age\"].mean(), inplace=True)\n",
    "age_bins = [0, 10, 18, 60, float(\"inf\")]\n",
    "age_labels = [\"child\", \"teen\", \"adult\", \"elder\"]\n",
    "test_df[\"Categorized_Age\"] = pd.cut(test_df[\"Age\"], bins=age_bins, labels=age_labels, right=True)\n",
    "#changing categorical into numerical\n",
    "le = LabelEncoder()\n",
    "#female is 0 and male is 1\n",
    "test_df[\"Sex\"] = le.fit_transform(test_df[\"Sex\"])\n",
    "#adult = 0, child = 1, teen = 3, elder = 2\n",
    "test_df[\"Categorized_Age\"] = le.fit_transform(test_df[\"Categorized_Age\"])\n",
    "\n",
    "\n",
    "test_df = test_df.drop([\"Name\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Embarked\"], axis=1)\n",
    "\n",
    "prediction = ensemble_classifier.predict(test_df)\n",
    "result = pd.DataFrame({'PassengerId': test_df[\"PassengerId\"], 'Survived': prediction})\n",
    "result.to_csv('Titanic.csv', index=False)\n",
    "result.name = \"Predicted Titanic Passenger Survivability\"\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not overfitting because the model is being ran over multiple folds and it is being ran that many times each time using k - 1 folds. Thus it is a more generic model instead of being generalized to the one dataset used to train it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Try reducing the dimension of the dataset and create a Naive Bayes model. Evaluate this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5642458100558659\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit_transform(train_df.drop([\"Survived\", \"Name\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Embarked\"], axis=1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reduced, train_df[\"Survived\"], test_size=0.2, random_state=50)\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Create an ensemble classifier using a combination of KNN, Decision Trees, and Naive Bayes models. Evaluate this classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.776536312849162\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         0\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_df = train_df.drop([\"Name\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Embarked\", \"Survived\"], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_df, survived, test_size = 0.2, random_state=50)\n",
    "\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "ensemble_classifier = VotingClassifier(estimators=[\n",
    "    ('knn', knn_classifier),\n",
    "    ('dt', dt_classifier),\n",
    "    ('nb', nb_classifier)\n",
    "], voting='hard')\n",
    "\n",
    "ensemble_classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = ensemble_classifier.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "#every new feature added to train, add to test \n",
    "#setting Cabin to either 1 or 0\n",
    "test_df.loc[test_df[\"Cabin\"].notnull(), \"Cabin\"] = 1\n",
    "test_df[\"Cabin\"].fillna(0, inplace=True)\n",
    "#adding Family members\n",
    "test_df[\"family_members\"] = test_df[\"SibSp\"] + test_df[\"Parch\"]\n",
    "#Any title that has a frequency of over 100 is considered common\n",
    "#These are Mr, Miss, and Mrs\n",
    "test_df[\"title_type\"] = test_df[\"Name\"].str.extract(\" ([A-Za-z]+)\\.\", expand=False)\n",
    "frequency = test_df[\"title_type\"].value_counts()\n",
    "common = frequency[frequency > 100].index\n",
    "test_df[\"title_type\"] = test_df[\"title_type\"].apply(lambda x: 1 if x in common else 0)\n",
    "#fare_price\n",
    "test_df[\"Fare\"].fillna(test_df[\"Fare\"].mean(), inplace=True)\n",
    "fare_data = np.array(test_df[\"Fare\"]).reshape(-1, 1)\n",
    "k_means = KMeans(n_clusters=5, random_state=50, n_init=10)\n",
    "k_means.fit(fare_data)\n",
    "centroids = k_means.cluster_centers_\n",
    "test_df[\"fare_price\"] = k_means.predict(fare_data)\n",
    "#categorizing the age\n",
    "test_df[\"Age\"].fillna(test_df[\"Age\"].mean(), inplace=True)\n",
    "age_bins = [0, 10, 18, 60, float(\"inf\")]\n",
    "age_labels = [\"child\", \"teen\", \"adult\", \"elder\"]\n",
    "test_df[\"Categorized_Age\"] = pd.cut(test_df[\"Age\"], bins=age_bins, labels=age_labels, right=True)\n",
    "#changing categorical into numerical\n",
    "le = LabelEncoder()\n",
    "#female is 0 and male is 1\n",
    "test_df[\"Sex\"] = le.fit_transform(test_df[\"Sex\"])\n",
    "#adult = 0, child = 1, teen = 3, elder = 2\n",
    "test_df[\"Categorized_Age\"] = le.fit_transform(test_df[\"Categorized_Age\"])\n",
    "\n",
    "\n",
    "test_df = test_df.drop([\"Name\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Embarked\"], axis=1)\n",
    "\n",
    "prediction = ensemble_classifier.predict(test_df)\n",
    "result = pd.DataFrame({'PassengerId': test_df[\"PassengerId\"], 'Survived': prediction})\n",
    "result.to_csv('titanic.csv', index=False)\n",
    "result.name = \"Predicted Titanic Passenger Survivability\"\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Update your kaggle submission using the best model you created (best model means the one that performed the best on your local evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/competitions/titanic/leaderboard?search=Calvin0824\n",
    "\n",
    "Kaggle User: Calvin0824  \n",
    "Kaggle Score: 0.78468  \n",
    "Kaggle Rank: 2245"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful code for the midterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "sns.set()\n",
    "\n",
    "# Get face data\n",
    "faces = fetch_lfw_people(min_faces_per_person=60)\n",
    "\n",
    "# plot face data\n",
    "fig, ax = plt.subplots(3, 5)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(faces.images[i], cmap='bone')\n",
    "    axi.set(xticks=[], yticks=[],\n",
    "            xlabel=faces.target_names[faces.target[i]])\n",
    "plt.show()\n",
    "\n",
    "# split train test set\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(faces.data, faces.target, random_state=42)\n",
    "\n",
    "pca = PCA(n_components=150, whiten=True)\n",
    "svc = SVC(kernel='rbf', class_weight='balanced')\n",
    "svcpca = make_pipeline(pca, svc)\n",
    "\n",
    "# Tune model to find best values of C and gamma using cross validation\n",
    "param_grid = {'svc__C': [1, 5, 10, 50],\n",
    "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "kfold = 10\n",
    "grid = GridSearchCV(svcpca, param_grid, cv=kfold)\n",
    "grid.fit(Xtrain, ytrain)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "# use the best params explicitly here\n",
    "pca = PCA(n_components=150, whiten=True)\n",
    "svc = SVC(kernel='rbf', class_weight='balanced', C=10, gamma=0.005)\n",
    "svcpca = make_pipeline(pca, svc)\n",
    "\n",
    "model = BaggingClassifier(svcpca, n_estimators=100).fit(Xtrain, ytrain)\n",
    "yfit = model.predict(Xtest)\n",
    "\n",
    "fig, ax = plt.subplots(6, 6)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(Xtest[i].reshape(62, 47), cmap='bone')\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.set_ylabel(faces.target_names[yfit[i]].split()[-1],\n",
    "                   color='black' if yfit[i] == ytest[i] else 'red')\n",
    "fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14)\n",
    "plt.show()\n",
    "\n",
    "mat = confusion_matrix(ytest, yfit)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=faces.target_names,\n",
    "            yticklabels=faces.target_names)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy = \", accuracy_score(ytest, yfit))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
